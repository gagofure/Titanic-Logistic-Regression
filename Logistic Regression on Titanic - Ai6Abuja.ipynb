{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fetching the training and test sets\n",
    "test = pd.read_csv('titanic-test.csv')\n",
    "train = pd.read_csv('titanic-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspecting the dimensions of out training and test sets\n",
    "print('Dimension of train: {0}'.format(train.shape))\n",
    "print(\"Dimension of test data: {0}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check survival Rates for Each of the Classes grouped by Sex\n",
    "sex_pivot = train.pivot_table(index=\"Sex\",values=\"Survived\")\n",
    "sex_pivot.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Survival rate by P'class alone\n",
    "class_pivot = train.pivot_table(index = 'Pclass',values = 'Survived',aggfunc = np.mean)\n",
    "class_pivot.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring and Converting the Age Column\n",
    "#train['Age'].describe() # Average age is 30 years,\n",
    "under_30 = train.query('Age <=30')\n",
    "under_30.shape[0]/train.shape[0] \n",
    "# 46% of the Passengers are 30 years and below. (irrespective of is.na) Nan will be treated l8r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how many people survived sef..\n",
    "survived = train.query('Survived ==1')\n",
    "died = train.query('Survived ==0')\n",
    "print(survived.shape); \n",
    "print(died.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting the Histogram Distribution\n",
    "survived.Age.plot.hist(alpha = 0.5, color = 'red', bins =50) # Lucky folks\n",
    "died.Age.plot.hist(alpha = 0.5, color = 'blue', bins =50) # May their sould rest in peace\n",
    "plt.legend(['Survived','Died'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(survived)/(len(survived) + len(died))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More People Survivie between 20 and 30 years than any other age range and more people within this age range didnt survive when compared to other age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lets see their death-sity. Attimes histogram can be confusing at time....\n",
    "survived.Age.plot.density(color = 'yellow')\n",
    "died.Age.plot.density(color = 'magenta')\n",
    "plt.legend(['Survived','Died'])\n",
    "plt.show() # Their deathsity's distributon is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut_points_1 = [-1, 0, 5, 12, 18, 25, 60, 100] # Randomly Selected, by my church mind\n",
    "Agelabels = ['Missing', 'Infant', 'Child', 'Teenager', 'Young Adult','Adult','Senior'] #Categories\n",
    "\n",
    "#function the processes  Age an\n",
    "def ProcessAge(df, cut_points,label_names):\n",
    "    \n",
    "    # -0.5 for missing ages\n",
    "    df['Age'] = df['Age'].fillna(-0.5) \n",
    "    \n",
    "    df['Age_Categories'] = pd.cut(df['Age'],cut_points,labels = label_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ProcessAge(train, cut_points = cut_points_1, label_names= Agelabels)\n",
    "test = ProcessAge(test,cut_points= cut_points_1, label_names= Agelabels)\n",
    "train.query(\"Age_Categories == 'Infant'\")\n",
    "\n",
    "train.pivot_table('Survived', index = 'Age_Categories', aggfunc= np.mean).plot.bar()\n",
    "plt.show() \n",
    "\n",
    "#Interestingly! The graph below shows that more infants survived that any other age_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets split the PClass column into dummy columns to cater for \n",
    "#1st, 2nd and 3rd Clas seperately\n",
    "\n",
    "def create_dummies(df, column_name):\n",
    "    dummies = pd.get_dummies(df[column], prefix = column_name)\n",
    "    df = pd.concat([df,dummies],axis =1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Pclass','Sex','Age_Categories']:\n",
    "    train = create_dummies(train,column)\n",
    "    test = create_dummies(test,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Creating a Logistic Regression object\n",
    "titanic_model = LogisticRegression()\n",
    "\n",
    "#Features we'll be using to train our model\n",
    "features = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
    "            'Age_Categories_Missing','Age_Categories_Infant','Age_Categories_Child',\n",
    "            'Age_Categories_Teenager','Age_Categories_Young Adult', \n",
    "            'Age_Categories_Adult','Age_Categories_Senior']\n",
    "\n",
    "'''\n",
    "NB\n",
    "Some Features are more important than the other. (Thats for another day)\n",
    "As per the Sklearn documentation, some classifiers are built in with an \n",
    "attribute which returns feature importances by simply typing in .featureimportances.\n",
    "\n",
    "You can try this out..\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_x = train[features]\n",
    "all_y = train['Survived']\n",
    "\n",
    "#Split the train test into train and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(all_x, all_y,\n",
    "                                                    test_size = 0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oya lets Train Our Model\n",
    "titanic_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating predictions\n",
    "predictions = titanic_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using confusion matrix to evaluate predictions from our model..\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "titanic_confuse_matrix = confusion_matrix(test_y,predictions)\n",
    "titanic_confuse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the confusion matrix using seaborn package\n",
    "import seaborn as sns\n",
    "sns.heatmap(titanic_confuse_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to measure the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy  = accuracy_score(test_y,predictions)\n",
    "print(accuracy) #78.7 not bad... Can your model predict a better accuracy score.. Give it a try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Till next time, Peace Out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
